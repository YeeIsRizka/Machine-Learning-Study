# -*- coding: utf-8 -*-
"""proyek-predictive-analytic.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1k_REuIR9ScIs7DE0MFH71NycEOg3rsJt

# Proyek Predictive Analytics: [Student Habits vs Academic Performance Dataset]
- **Nama:** Rizka Alfadilla
- **Email:** rizkaal874@gmail.com
- **ID Dicoding:** rizka_alfadilla

## Import Semua Packages/Library yang Digunakan

Pada bagian ini, dilakukan import seluruh library yang akan digunakan dalam proyek ini. Library yang digunakan meliputi Pandas, Matplotlib, Seaborn, dan library machine learning dari scikit-learn.
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import  OneHotEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from scipy.stats import uniform, randint

"""## Data Loading

Dataset = https://www.kaggle.com/datasets/jayaantanaath/student-habits-vs-academic-performance/data

Dataset diunduh dari Kaggle (Student Habits vs Academic Performance Dataset). Dataset ini berisi informasi kebiasaan siswa terkait waktu belajar, media sosial, diet, dll. Dataset dimuat menggunakan Pandas dan akan dilakukan pemeriksaan informasi dataset.
"""

# Load hour.csv dari folder data dan tampilkan
df = pd.read_csv('student_habits_performance.csv')
df

"""### Exploratory Data Analysis (EDA)

Pada bagian ini, dilakukan EDA untuk memahami distribusi data dan missing values. Visualisasi menggunakan Seaborn dan Matplotlib.
"""

df.info()

"""Dataset memiliki 1.000 sampel dengan 16 fitur, terdiri dari 7 fitur kategorikal (`object`), 6 fitur numerik kontinu (`float64`), dan 3 fitur numerik diskrit (`int64`). Ini menunjukkan bahwa dataset cukup beragam dalam tipe datanya, sehingga diperlukan teknik preprocessing berbeda untuk masing-masing tipe data (misalnya, encoding untuk data kategorikal dan standarisasi untuk data numerik). Terlihat juga Fitur `parental_education_level` memiliki 91 missing values."""

df.describe()

"""Nilai ujian (`exam_score`) sebagai target prediksi memiliki rata-rata 69,6, dengan sebagian besar siswa mendapatkan nilai antara 58,5 hingga 81,3. Variabilitas skor ujian yang cukup tinggi menunjukkan adanya perbedaan signifikan dalam performa siswa, yang dapat menjadi fokus utama dalam proses analisis selanjutnya."""

# Membuat dataframe untuk kondisi dataset
dataset_info = pd.DataFrame({
    "Tipe Data": df.dtypes,
    "Jumlah Missing": df.isnull().sum(),
    "Jumlah Unik": df.nunique(),
    "Nilai Unik Contoh": [df[col].unique()[:5].tolist() for col in df.columns]
})

dataset_info

print("Jumlah duplikasi: ", df.duplicated().sum())

"""Tidak ada duplikasi yg ditemukan. Secara keseluruhan, sebagian besar fitur memiliki distribusi data yang beragam, terutama pada fitur numerik seperti `study_hours_per_day`, `social_media_hours`, dan `attendance_percentage`. Fitur `parental_education_level` memiliki missing values yang perlu diatasi untuk memastikan kelengkapan data sebelum proses modeling."""

# Melihat jumlah missing values sebelum imputasi
print("Jumlah missing values sebelum imputasi:")
print(df['parental_education_level'].isnull().sum())

# Imputasi missing values dengan 'Unknown'
# Mengatasi warning dengan assignment langsung
df['parental_education_level'] = df['parental_education_level'].fillna('Unknown')

# Melihat jumlah missing values setelah imputasi
print("\nJumlah missing values setelah imputasi:")
print(df['parental_education_level'].isnull().sum())

# Mengecek distribusi setelah imputasi
print("\nDistribusi 'parental_education_level' setelah imputasi:")
print(df['parental_education_level'].value_counts())

"""Metode mengatasi missing value yang digunakan adalah imputasi menggunakan string 'Unknown', artinya semua nilai yang kosong (`NaN`) diisi dengan label `'Unknown'`. Metode ini dipilih karena parental_education_level adalah fitur kategorikal, sehingga tidak tepat jika dilakukan imputasi menggunakan mean, median, atau modus (yang umumnya digunakan untuk data numerik). Selain itu, mengganti nilai `NaN` dengan `'Unknown'` juga memastikan bahwa informasi missing values tetap terdeteksi sebagai kategori khusus tanpa mengubah distribusi data."""

# Fitur numerik
numerical_features = ['age', 'study_hours_per_day', 'social_media_hours',
                      'netflix_hours', 'attendance_percentage', 'sleep_hours',
                      'exercise_frequency', 'mental_health_rating', 'exam_score']
# Fitur kategorikal
categorical_features = ['gender', 'part_time_job', 'diet_quality',
                        'parental_education_level', 'internet_quality',
                        'extracurricular_participation']

"""Pembagian fitur numerik dan kategorikal ini dilakukan untuk mempermudah proses eksplorasi selanjutnya."""

# Loop untuk setiap fitur kategorikal
for feature in categorical_features:
    # Hitung jumlah sampel dan persentase
    count = df[feature].value_counts()
    percent = 100 * df[feature].value_counts(normalize=True)

    # Membuat dataframe untuk visualisasi
    df_cat = pd.DataFrame({'jumlah sampel': count, 'persentase': percent.round(1)})
    print(f"\nDistribusi untuk fitur: {feature}\n")
    print(df_cat)
    print("-" * 50)

    # Visualisasi bar plot
    plt.figure(figsize=(8, 6))
    ax = count.plot(kind='bar', color='skyblue', edgecolor='black')
    plt.title(f"Distribusi {feature}")
    plt.xlabel(feature)
    plt.ylabel("Jumlah Sampel")
    plt.xticks(rotation=45)
    plt.grid(axis='y', linestyle='--', alpha=0.7)

    # Menambahkan jumlah sampel di atas bar
    for i, val in enumerate(count):
        plt.text(i, val + 1, str(val), ha='center', va='bottom', fontsize=10, fontweight='bold', color='black')

    plt.tight_layout()
    plt.show()

"""Sebagian besar siswa (78.5%) tidak memiliki pekerjaan paruh waktu, sementara 21.5% memiliki pekerjaan paruh waktu. Hampir separuh siswa memiliki kualitas internet yang baik (Good, 44.7%), sementara 16.2% siswa memiliki kualitas internet yang buruk (Poor).  Sebanyak 68.2% siswa tidak terlibat dalam kegiatan ekstrakurikuler, sedangkan 31.8% siswa aktif dalam kegiatan tersebut. Siswa yang memiliki pekerjaan paruh waktu, mengikuti ekrakulikuler, dam internet yg buruk berpotensi memiliki jam belajar lebih sedikit, sehingga fitur ini mungkin berkorelasi dengan `study_hours_per_day` dan `exam_score`.


"""

# Visualisasi histogram untuk semua fitur numerik
df[numerical_features].hist(bins=50, figsize=(20, 15), color='skyblue', edgecolor='black')
plt.suptitle("Distribusi Fitur Numerik", fontsize=16, y=1.02)
plt.tight_layout()
plt.show()

"""`exam_score` dan `attendance_percentage` cenderung left-skewed, menunjukkan mayoritas siswa memiliki nilai tinggi dan sering masuk. Fitur seperti `study_hours_per_day` dan `sleep_hours` memiliki distribusi mendekati normal, mencerminkan variasi alami. Sementara itu, `netflix_hours` dan `social_media_hours` bersifat right-skewed, menandakan sebagian besar mahasiswa hanya sedikit melakukannya. Sisanya tersebar merata, menunjukkan data yang representatif.  """

# Visualisasi rata-rata `exam_score` berdasarkan fitur kategorikal
for col in categorical_features:
    plt.figure(figsize=(12, 6))

    # Menghitung rata-rata `exam_score`
    data = df.groupby(col)['exam_score'].mean().reset_index()

    # Plot barplot
    ax = sns.barplot(x=col, y="exam_score", data=data, palette="Set3", ci=None)
    plt.title(f"Rata-rata 'exam_score' terhadap {col}")
    plt.xticks(rotation=45)
    plt.ylabel("Rata-rata Exam Score")
    plt.xlabel(col)

    # Menampilkan rata-rata `exam_score` di atas bar
    for i, bar in enumerate(ax.patches):
        height = bar.get_height()
        mean_score = round(height, 2)  # Membulatkan rata-rata exam_score
        ax.text(
            bar.get_x() + bar.get_width() / 2,  # Posisi x (tengah bar)
            height + 0.5,  # Posisi y (sedikit di atas bar)
            f'{mean_score}',  # Teks rata-rata exam_score
            ha='center', va='bottom', fontsize=10, fontweight='bold', color='black'
        )

    plt.tight_layout()
    plt.show()

"""Rata-rata `exam_score` dengan setiap fitur kategorikal sangat seimbang. Secara tidak langsung ini sudah menjawab potensi fitur fitur ini dengan `exam_score` tidak terlalu besar, karena persebaran datanya sendiri sangat merata."""

# Mengamati hubungan antar fitur numerik dengan fungsi pairplot()
sns.pairplot(df, diag_kind = 'kde')

"""Terlihat pola dari sebaran data (titik-titik) pada gambar di atas, hanya `study_hours_per_day` yg memiliki korelasi positif. Hal ini ditandai dengan meningkatnya variabel pada sumbu y saat terjadi peningkatan variabel pada sumbu x. Selain daripada itu `social_media_hour` dan `netflix_hours` juga sedikit mengarah membentuk korelasi negatif yang ditandai dengan menurunnya variabel y saat terjadi kenaikan pada variabel x.  Sisanya sebaran pada data menunjukkan pola acak, artinya tidak terlalu ada korelasi pada data."""

# Membuat heatmap untuk korelasi fitur numerik
plt.figure(figsize=(10, 8))
correlation_matrix = df[numerical_features].corr().round(2)

# Plot heatmap
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title("Correlation Matrix untuk Fitur Numerik", fontsize=20)
plt.xticks(rotation=45, ha='right')
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()

"""Fitur `study_hours_per_day` menunjukkan korelasi sangat kuat terhadap `exam_score` dengan nilai +0.83, menandakan bahwa semakin lama waktu belajar per hari, semakin tinggi kemungkinan nilai ujian mahasiswa. Sebaliknya, `social_media_hours` dan `netflix_hours` berkorelasi negatif (-0.17) dengan `exam_score`, mengindikasikan bahwa penggunaan waktu berlebih pada aktivitas ini mungkin berdampak pada penurunan performa akademik. Fitur lainnya seperti `age`tidak memiliki pengaruh korelatif yang signifikan terhadap skor ujian.

## Data Preparation

### Data Preprocessing

Pada tahap ini, dilakukan preprocessing data. Langkah-langkah yang dilakukan meliputi penghapusan kolom yang tidak relevan, encoding, dan standarisasi data. One-Hot Encoding, Label Encoding, dan Standarisasi digunakan untuk mengubah data agar dapat lebih efektif diproses oleh model.
"""

df.drop(['age'], inplace=True, axis=1)
df.drop(['student_id'], inplace=True, axis=1)

df.info()

"""Pertama-tama menghapus kolom yg dianggap kurang relevan dan tidak  terlalu memiliki korelasi pada `exam_score`.

- `student_id`: Kolom ini hanya berfungsi sebagai identitas unik siswa dan tidak memiliki pengaruh langsung terhadap target exam_score.
- `age`: Berdasarkan analisis korelasi, kolom ini memiliki korelasi yang sangat rendah dengan exam_score (-0.01). Oleh karena itu, kolom ini dihapus untuk mengurangi noise dalam data.
"""

# Label Encoding untuk fitur ordinal
label_features = ['diet_quality', 'parental_education_level', 'internet_quality']

# Inisialisasi Label Encoder
le = LabelEncoder()

# Melakukan Label Encoding
for feature in label_features:
    df[feature] = le.fit_transform(df[feature])

print("\nData setelah Label Encoding:")
df[label_features].head()

"""Pada tahap ini dilakukan label encoding pada fitur ordinal untuk mempertahankan informasi urutan (ranking). Fitur yang diencoding adalah `diet_quality`, `parental_education_level` dan`internet_quality`. Fitur-fitur ini memiliki urutan nilai yang harus dipertahankan, sehingga menggunakan One Hot Encoding akan menyebabkan hilangnya informasi urutan tersebut."""

# One-Hot Encoding untuk fitur nominal
encoder = OneHotEncoder(drop='first', sparse_output=False)  # drop='first' untuk menghindari dummy variable trap

# Fitur nominal yang akan di-One Hot Encoding
one_hot_features = ['gender', 'part_time_job', 'extracurricular_participation']

# Melakukan One Hot Encoding
encoded_data = encoder.fit_transform(df[one_hot_features])

# Mendapatkan nama kolom hasil encoding
encoded_columns = encoder.get_feature_names_out(one_hot_features)

# Membuat DataFrame dari hasil encoding
encoded_df = pd.DataFrame(encoded_data, columns=encoded_columns)

# Menggabungkan hasil encoding ke DataFrame asli
df = pd.concat([df.drop(one_hot_features, axis=1), encoded_df], axis=1)

# Menampilkan hasil One Hot Encoding
print("\nData setelah One Hot Encoding:")
df.head()

"""Pada tahap ini dilakukan One Hot Encoding pada fitur nominal yang tidak memiliki urutan tertentu. Fitur-fitur ini merupakan kategori non-ordinal sehingga tidak ada hubungan urutan antara kategori tersebut. Menggunakan Label Encoding pada fitur ini dapat menyebabkan model mengasumsikan adanya hubungan urutan (`0 < 1 < 2`), yang sebenarnya tidak ada."""

numerical_features = ['study_hours_per_day', 'social_media_hours',
                      'netflix_hours', 'attendance_percentage', 'sleep_hours',
                      'exercise_frequency', 'mental_health_rating']

# Inisialisasi StandardScaler
scaler = StandardScaler()

# Melakukan standarisasi (hanya untuk fitur numerik)
df[numerical_features] = scaler.fit_transform(df[numerical_features])

# Menampilkan hasil standarisasi
print("\nData setelah Standarisasi:")
df.head()

"""Standarisasi dilakukan pada fitur numerik agar semua fitur berada pada skala yang sama (`mean = 0, std = 1`). Jika fitur memiliki skala yang berbeda-beda, maka fitur dengan skala besar akan mendominasi model, meskipun pengaruhnya sebenarnya tidak signifikan.

### Split Dataset
"""

# Split Dataset
X = df.drop('exam_score', axis=1)
y = df['exam_score']

# Membagi dataset menjadi training set (80%) dan testing set (20%)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Menampilkan ukuran dataset
print(f"Ukuran X_train: {X_train.shape}")
print(f"Ukuran X_test: {X_test.shape}")
print(f"Ukuran y_train: {y_train.shape}")
print(f"Ukuran y_test: {y_test.shape}")

"""Dataset dibagi menjadi training set (80%) dan testing set (20%). 80:20 adalah dsalah satu jumlah pembagian yg paling umum untuk saat ini.

## Model Development

Proses ini melakukan hyperparameter tuning menggunakan GridSearchCV untuk tiga model (Linear Regression, Random Forest, Gradient Boosting) berdasarkan parameter yang telah ditentukan, kemudian mengevaluasi performa setiap model menggunakan metrik MSE, MAE, dan R² pada data training dan testing, serta menyimpan hasil evaluasinya dalam bentuk DataFrame untuk analisis lebih lanjut.
"""

# === 1. Parameter distributions ===
param_distributions = {
    "Linear Regression": {
        "fit_intercept": [True, False],
        "copy_X": [True, False],
        "positive": [True, False]
    },
     "Random Forest": {
        "n_estimators": [50, 100, 150, 200],
        "max_depth": [3, 5, 7, 10],
        "min_samples_split": [2, 5, 10],
        "min_samples_leaf": [1, 2, 4]
    },
    "Gradient Boosting": {
        "n_estimators": [50, 100, 200],
        "max_depth": [3, 5, 7],
        "learning_rate": [0.01, 0.05, 0.1, 0.2],
        "subsample": [0.5, 0.7, 1.0]
    }
}

# === 2. Model list ===
model_list = {
    "Linear Regression": LinearRegression(),
    "Random Forest": RandomForestRegressor(random_state=42),
    "Gradient Boosting": GradientBoostingRegressor(random_state=42)
}

# === 3. Tuning, Training, Evaluation ===
results = []

for model_name, model in model_list.items():
    print(f"\nTuning {model_name}...")

    search = GridSearchCV(  # Use GridSearchCV instead for small parameter space
        estimator=model,
        param_grid=param_distributions[model_name],
        cv=3,
        scoring='neg_mean_squared_error',
        n_jobs=-1,
        verbose=1
    )

    # Melakukan pencarian hyperparameter terbaik
    search.fit(X_train, y_train)
    best_model = search.best_estimator_

    # Prediksi
    train_pred = best_model.predict(X_train)
    test_pred = best_model.predict(X_test)

    # Evaluasi
    train_mse = mean_squared_error(y_train, train_pred)
    test_mse = mean_squared_error(y_test, test_pred)
    train_mae = mean_absolute_error(y_train, train_pred)
    test_mae = mean_absolute_error(y_test, test_pred)
    train_r2 = r2_score(y_train, train_pred)
    test_r2 = r2_score(y_test, test_pred)

    # Menyimpan hasil evaluasi
    results.append({
        "Model": model_name,
        "Best Params": search.best_params_,
        "Train MSE": f"{train_mse:.2f}",
        "Test MSE": f"{test_mse:.2f}",
        "Train MAE": f"{train_mae:.2f}",
        "Test MAE": f"{test_mae:.2f}",
        "Train R2": f"{train_r2:.2f}",
        "Test R2": f"{test_r2:.2f}"
    })

    print(f"{model_name}: Train MSE = {train_mse:.2f}, Test MSE = {test_mse:.2f}, Train R2 = {train_r2:.2f}, Test R2 = {test_r2:.2f}")

# === 4. Simpan Results ===
df_results = pd.DataFrame(results)

"""Linear Regression menunjukkan performa yang paling stabil tanpa overfitting dengan R² sebesar 0.90, sementara Random Forest mengalami overfitting dan Gradient Boosting memiliki performa yang lebih baik daripada Random Forest namun masih sedikit overfit.

## Evaluasi Model
"""

print("\nHasil Evaluasi Model:")
df_results

"""Linear Regression menunjukkan performa yang paling stabil dengan MSE dan MAE yang relatif rendah baik pada data training (MSE: 28.69, MAE: 4.22) maupun testing (MSE: 26.24, MAE: 4.15), sementara Random Forest mengalami overfitting karena MSE training jauh lebih rendah (6.60) dibandingkan testing (38.39), dan Gradient Boosting berhasil mengurangi overfitting dengan R² yang lebih tinggi pada testing (0.89) dibanding Random Forest (0.85)."""